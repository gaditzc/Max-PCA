\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}

\title{Max PCA}
\author{Gad Zalcberg }
\date{January 2019}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Problem Introduction}
Consider the minimization of a general objective function
$f(X)$ over all low-rank $n\times n$ matrices:

\begin{equation}
\begin{split}
\min_{X\in \mathbb{R}^{n\times n}} & f\left(X\right)\\
s.t.\quad X & \preceq I\\
rank\left(X\right) &\le r\\
Trace\left(X\right) &\le r
\end{split}
\end{equation}

where the objective function $f:\mathbb{R}^{n\times n} \rightarrow \mathbb{R}$ is smooth.
To cope the none convex constaraint, we factorize the variable into $X = U U^T$, and optimize over the $n \times r$ matrix $U$. Note tha we have: $UU^T\preceq I_{n\times n}\Rightarrow U^TU\preceq I_{r\times r}\Rightarrow Trace\left(U^TU\right)\le r\Rightarrow Trace\left(UU^T\right)\le r$. So with this parameterization of X, we can recast (1) into the following program:

\begin{equation}
    \min_{U\in \mathbb{R}^{n\times r}, UU^T\preceq I} h\left(U\right):=f\left(UU^T\right)
\end{equation}

We provide a geometric analysis for the factored program (2) and show that, under certain conditions on $f(X)$, all critical points of the objective function $h\left(U\right)$ are well-behaved.


\section{Condition to global minimum of $f$ under rank and convex constraint:}

Before presenting the main results, we lay out the necessary assumptions on the objective function $f(X)$. As is known, without any assumptions on the problem, even minimizing traditional quadratic objective functions is challenging. For this purpose, we focus on the model where $f(X)$ is:

'$(2r, 4r)-restricted\; strongly\; convex\; and\; smooth$', i.e., for any $n\times n$ matrices $X, G\preceq I$ with: $Trace\left(X\right), Trace\left(G\right)\le r$, $rank(X) \le 2r$ and $rank(G) \le 4r$, the Hessian of $f(X)$ satisfies:

\begin{align}
\alpha\left\Vert G\right\Vert^2_F\le \left[\nabla^2f\left(X\right)\right]\left(G,G\right)\le \beta\left\Vert G\right\Vert^2_F
\end{align}

for some positive $\alpha$ and $\beta$.

\begin{proposition}[Condition to global minimum of $f$]
Consider the minimization of a general objective function $f\left(X\right)$ over low-rank $n\times m$ matrices in the convex set $X \preceq I, Trace\left(X\right) \le r$:

\begin{align*}
    \min_{X} & f\left(X\right)\\
    X & \preceq I\\
    rank\left(X\right) & \le r\\
    Trace\left(X\right) & \le r
\end{align*}

Suppose $f\left(x\right)$ satisfies the $\left(2r,4r\right)$-restricted strong convexity and smoothness condition with positive $\alpha$ and $\beta$, and assume for any $G\preceq I$ with $Trace\left(G\right)\le r, \;rank\left(G\right)\le2r$ we have: $\nabla f^{T}\left(X^{*}\right)G\ge0$ , than $X^{*}$ is the optimal solution of the problem.

\end{proposition}

Proof of proposition 1: For any $X\in\mathbb{R}^{n\times n}$ with $rank\left(X\right)\le r$, the second order Taylor expansion gives:
\begin{align*}
    f\left(X\right)=f\left(X^{*}\right)+\left\langle \nabla f\left(X^{*}\right),\left(X-X^{*}\right)\right\rangle +\frac{1}{2}\left[\nabla^{2}f\left(\widetilde{X}\right)\right]\left(X-X^{*},X-X^{*}\right)
\end{align*}

where $\widetilde{X}=tX+\left(1-t\right)X^{*}$ for some $t\in\left[0,1\right]$. Since $rank\left(X\right)\le r$ and $rank\left(X^{*}\right)\le r$ we get $rank\left(X-X^{*}\right)\le2r$. We also have the constraints: $\preceq I$, $Trace\left(\cdot\right)\le r$ which are convex. So by condition, we get: $\left[\nabla^{2}f\left(\widetilde{X}\right)\right]\left(X-X^{*},X-X^{*}\right)\ge\alpha\left\Vert X-X^{*}\right\Vert _{F}^{2}$ and $\left\langle \nabla f\left(X^{*}\right),\left(X-X^{*}\right)\right\rangle \ge0$ and:

\begin{align*}
    f\left(X\right)\ge f\left(X^{*}\right)+0+\frac{\alpha}{2}\left\Vert X-X^{*}\right\Vert _{F}^{2}
\end{align*}


\section{Optimal solution of the factorized problem:}

Before continuing this geometry-based argument, it is essential to have a good understanding of the domain of the
factored problem and establish a metric for this domain. Since for any $U$, $\phi\left(U\right)=\phi\left(UR\right)$ where $R\in \mathbb{O}_r$, the domain of the factored objective function $h\left(U\right)$ is stratified into equivalence classes. The matrices in each of these equivalence classes differ by an orthogonal transformation. One implication is that, when working in the factored space, we should
consider all factorizations of $X^*$: 
\begin{align*}
    \mathcal{A}^*=\left\{ U^*\in \mathbb{R}^{n\times r}:\phi\left(U\right)=X^*\right\} 
\end{align*}

A second implication is that when considering the distance between two points $U_1$ and $U_2$ , one should use the distance between their corresponding equivalence classes:

\begin{align*}
    d\left(U_1,U_2\right)=\min_{R_1,R_2\in \mathbb{O}_r}\left\Vert U_1R_1 - U_2R_2\right\Vert_F = \min_{R\in \mathbb{O}_r}\left\Vert U_1 - U_2R\right\Vert _F
\end{align*}

The second minimization problem is known as the orthogonal Procrustes problem. 

\section{Main Theorem:}

We begin with the notion of strict saddles and the strict saddle property.\\
Let $S$ be a convex set. Suppose $h:S\rightarrow \mathbb{R}$ is a twice continuously differentiable objective function:

\begin{definition}[Critical points]
We say $X^*$ a critical point if for any $G\in S$ we have: $\left<\nabla h\left(X^{*}\right),G\right>\ge0$.
\end{definition}

\begin{definition}[Strict saddles]
A critical point $X^*$ is a strict saddle if there exist $G\in S$ s.t. $\left[\nabla^2 h\left(X^*\right)\right]\left(G-X^*,G-X^*\right) < 0$.
\end{definition}

\begin{definition}[Strict saddle property]
A twice differentiable function satisfies the strict saddle property if each critical point either corresponds to a local minimum or is a strict saddle.
\end{definition}

Our main argument is that, under certain conditions on $f(X)$, the objective function $h(W)$ has no spurious local minima and satisfies the strict saddle property. This is equivalent to categorizing all the critical points into two types: 1) the global minima which correspond to the global solution of the original convex problem (1) and 2) strict saddles such that the Hessian matrix $\nabla^2h\left(W\right)$ evaluated at these points has a strictly negative eigenvalue. We formally establish this in the following theorem:

\begin{theorem}
Suppose that the function $f(X)$ satisfies the '$(2r, 4r)-$restricted strong convexity and smoothness' condition (3) with positive constants $\alpha$ and $\beta$ satisfying $\frac{\beta}{\alpha} \le 1.5$ and that the function $f(X)$ has a critical point $x\in \mathbb{R}^{n\times m}$ with $rank(X^*) = r$. Then $h(U)$ has no spurious local minima, i.e., any local minimum of $h(U)$ is a global minimum corresponding to the global solution of the original problem (1): $UU^T = X^*$. In addition, $h(U)$ obeys the strict saddle property that any critical point not being a local minimum is a strict saddle with:
\begin{align*}
    \left[\nabla^{2}h\left(U\right)\right]\left(\Delta,\Delta\right)\le-0.19\alpha\sigma_r\left(X^*\right)\left\Vert\Delta\right\Vert^2_F
\end{align*}

For some $\Delta$ which setisfies $\Delta\Delta^T\preceq I$.
\end{theorem}


\section{Useful Results:}

\subsection{Gradient and Hessian expressions for $\rho\left(W\right)$:}

\subsubsection{Gradient:}
\begin{align*}
    \nabla h\left(U\right)=2\nabla f\left(UU^T\right)U
\end{align*}

\subsubsection{Hessian quadrature form:}
For any $\Delta\in \mathbb{R}^{n\times r}$:
\begin{align*}
    \left[\nabla^2h\left(U\right)\right]\left(\Delta,\Delta\right)=2\left<\nabla f\left(UU^T\right),\Delta\Delta^T\right> + \left[\nabla^2 f\left(UU^T\right)\right]\left(\Delta U^T+U\Delta^T,\Delta U^T+U\Delta^T\right)
\end{align*}

\subsection{Useful Lemmas:}
\begin{lemma} \label{leamma_1}
Suppose a function $f\left(X\right)$ satisfies the '(2r,4r)-restricted strong convexity and smoothness' condition (3) with positive $\alpha$ and $\beta$. Than for any $n\times n$ matrices Z,G,H of rank at most 2r we have:
\begin{align*}
    \left\vert\frac{2}{\alpha + \beta}\left[\nabla^2 f\left(Z\right)\right]\left(G,H\right)-\left<G,H\right>\right\vert\le \frac{\alpha - \beta}{\alpha + \beta}\left\Vert G\right\Vert_F\left\Vert H\right\Vert_F
\end{align*}
\end{lemma}

\begin{lemma} \label{lemma_2}
Suppose $f\left(X\right)$ satisfies the '(2r,4r)-restricted strong convexity and smoothness' condition (3). For any critical point $U$ of (5) let $P_U\in\mathbb{R}^{n\times n}$ be the orthogonal projector onto the column space of $U$. Then:
\begin{align*}
    \left\Vert \left(UU^T-U^*{U^*}^T\right)P_U\right\Vert_F\le2\frac{\alpha - \beta}{\alpha + \beta}\left\Vert X-X^*\right\Vert_F
\end{align*}
\end{lemma}

Proof: \\
Let $X=UU^T$ and $X^*=U^*{U^*}^T$. We start with the critical point condition: $\left<\nabla f\left(X\right)U, G\right>\ge0$ for all $G$ satisfies $GG^T\le I$, which implies:
\begin{align*}
    &\left<\nabla f\left(X\right), \left(X-X^*\right)P_U\right>=\left<\nabla f\left(X\right)U, \left(X-X^*\right)U^\dagger\right>\ge0\\
    &\Rightarrow\left<\nabla f\left(X^*\right) + \int_{0}^{1}\left[\nabla^2f\left(tX+\left(1-t\right)X^*\right)\right]\left(X-X^*\right)dt, \left(X-X^*\right)P_U\right>\ge0\\
    &\Rightarrow\left<\nabla f\left(X^*\right), \left(X-X^*\right)P_U\right> + \left[ \int_{0}^{1}\left[\nabla^2f\left(tX+\left(1-t\right)X^*\right)\right]dt\right]\left(\left(X-X^*\right), \left(X-X^*\right)P_U\right)\ge0\\
    &\Rightarrow\frac{2}{\alpha+\beta}\left<\nabla f\left(X^*\right), \left(X-X^*\right)P_U\right> +\left<\left(X-X^*\right), \left(X-X^*\right)P_U\right> - \left<\left(X-X^*\right), \left(X-X^*\right)P_U\right>\\ + &\left\frac{2}{\alpha+\beta}[ \int_{0}^{1}\left[\nabla^2f\left(tX+\left(1-t\right)X^*\right)\right]dt\right]\left(\left(X-X^*\right), \left(X-X^*\right)P_U\right)\ge0
\end{align*}

\begin{lemma}[From Tu's paper, proved there] \label{lemma_3}
 For any matrices $C,D\in\mathbb{R}^{n\times r}$ with rank $r$, let $R =\arg \min_{R^{'} \in\mathcal{O}_r}\left\Vert C-DR^{'}\right\Vert_F$. Then
 \begin{align*}
     \frac{\left\Vert CC^T-DD^T\right\Vert_F^2}{\left\Vert C-DR\right\Vert_F^2}\ge 2\left(\sqrt{2}-1\right)\sigma_r^2\left(D\right)
 \end{align*}
\end{lemma}

\begin{lemma}[From Li's paper, proved there] \label{lemma_4}
 For any matrices $C,D\in\mathbb{R}^{n\times r}$, let $P_c$ be the orthogonal projector onto the range of $C$. let $R =\arg \min_{R^{'} \in\mathcal{O}_r}\left\Vert C-DR^{'}\right\Vert_F$. Than 
 \begin{align*}
     \left\Vert C\left(C-DR\right)^T\right\Vert^2_F\le\frac{1}{8}\left\Vert CC^T-DD^T\right\Vert^2_F + \left(3 + \frac{1}{2\left(\sqrt{2}- 1\right)}\right)\left\Vert \left(CC^T-DD^T\right)P_C\right\Vert^2_F
 \end{align*}
\end{lemma}

\section{Proof Of The Main Theorem:}

Our main argument involves showing that each critical point $U$ of $h$ either corresponds to the global solution of (1) or is a strict saddle whose Hessian has $\left[\nabla^2 h\left(U\right)\right]\left(U-U^*R,U-U^*R\right) < 0$ where $R=\arg\min_{R^{'}\in\mathcal{O}_r}\left\Vert U-U^*R^{'}\right\Vert_F$. Concretely, denote the set of critical points of $h\left(U\right)$ by:

\begin{align*}
    \mathcal{C}:=\left\{U\in\mathbb{R}^{n\times r}:U'{U'}^T\preceq I\Rightarrow \left<\nabla h\left(U\right),U'\right>\ge0\right\}
\end{align*}

We separate $\mathcal{C}$ into two subsets:

\begin{align*}
    \mathcal{C}_1:=\mathcal{C} \cap \left\{U\in\mathbb{R}^{n\times r}:UU^T=X^*\right\}\\
    \mathcal{C}_2:=\mathcal{C} \cap \left\{U\in\mathbb{R}^{n\times r}:UU^T\ne X^*\right\}
\end{align*}

satisfying $\mathcal{C}_1\cup \mathcal{C}_2 = \mathcal{C}$. Obviously $\mathcal{C}_1$ is the set of global minima. We will show that $\mathcal{C}_2$ is set of saddle points.

\subsection{The Formal Proof:}

To show that, it is sufficient to find a direction $\Delta$ along which the Hessian has a strictly negative curvature for each of these points. We construct $\Delta = U-U^*R$ the difference from $U$ to its nearest global factor $U^*$. Then we evaluate the Hessian bilinear form along the direction $\Delta$:
\begin{align}\label{bilinear_form}
\begin{split}
    \left[\nabla^2h\left(U\right)\right]\left(\Delta,\Delta\right)= & 
    2\underbrace{\left<\nabla f\left(UU^T\right),\Delta\Delta^T\right>}_{\Pi_{1}}\\
    & +\underbrace{\left[\nabla^2 f\left(UU^T\right)\right]\left(\Delta U^T+U\Delta^T,\Delta U^T+U\Delta^T\right)}_{\Pi_{2}} 
\end{split}
\end{align}

\subsubsection{Bounding $\Pi_1$:}
\begin{align*}
    \Pi_1 \le & -\alpha\left\Vert X-X^*\right\Vert^2_F 
\end{align*}

\subsubsection{Bounding $\Pi_2$:}
\begin{align*}
    \Pi_2 = & \left[\nabla^2 f\left(UU^T\right)\right]\left(\Delta U^T+U\Delta^T,\Delta U^T+U\Delta^T\right) \\
    \le & \beta\left\Vert \Delta U^T+U\Delta^T\right\Vert^2_F \\
    \le & 4\beta\left\Vert U \Delta^T \right\Vert^2_F\\
    = & 4\beta\left\Vert U\left(U-U^*R\right)^T\right\Vert^2_F \\
    \overset{\left(i\right)}{\le} & 4\beta\left[\frac{1}{8}\left\Vert UU^T-U^*{U^*}^T\right\Vert^2_F + \left(3 + \frac{1}{2\left(\sqrt{2}- 1\right)}\right)\left\Vert \left(UU^T-U^*{U^*}^T\right)P_U\right\Vert^2_F\right]\\
    \overset{\left(ii\right)}{\le} & \beta\left[\frac{1}{2}\left\Vert X-X^*\right\Vert^2_F + \left(12 + \frac{2}{\left(\sqrt{2}- 1\right)}\right)\left(\frac{\alpha - \beta}{\alpha + \beta}\right)^2\left\Vert X-X^*\right\Vert_F^2\right]\\
    = & \beta\left[\left(\frac{1}{2} + \left(12 + \frac{2}{\left(\sqrt{2}- 1\right)}\right)\left(\frac{\alpha - \beta}{\alpha + \beta}\right)^2\right)\left\Vert X-X^*\right\Vert_F^2\right]\\
    \overset{\left(iv\right)}{\le} & 1.76\alpha\left\Vert X-X^*\right\Vert_F^2 \\
\end{align*}

$\left(i\right)$ by lemma \ref{lemma_4}, $\left(ii\right)$ by lemma \ref{lemma_2}, and $\left(iv\right)$ since $\frac{\beta}{\alpha}\le1.5$. \\

And finally after substituting into \ref{bilinear_form} we get:
\begin{align*}
    \left[\nabla^2h\left(U\right)\right]\left(\Delta,\Delta\right)= & \Pi_1 + \Pi_2 \le -0.24\alpha\left\Vert X-X^*\right\Vert^2_F \overset{\left(v\right)}{\le}  -0.19\alpha\sigma_r\left(U^*\right)^2\left\Vert\Delta\right\Vert^2_F
\end{align*}

$\left(v\right)$ by lemma \ref{lemma_3}.

\end{document}
